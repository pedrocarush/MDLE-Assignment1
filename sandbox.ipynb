{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from itertools import combinations\n",
    "from typing import Iterable, Any"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/02 18:56:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('SandboxAssign1') \\\n",
    "    .config('spark.master', 'local[*]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .csv('conditions.csv.gz') \\\n",
    "    .drop('START', 'STOP', 'ENCOUNTER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_description_df = df \\\n",
    "    .select('CODE', 'DESCRIPTION') \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('DESCRIPTION').distinct()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-priori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_threshold = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('frequent_diseases_k1'):\n",
    "    frequent_diseases_k1 = df \\\n",
    "        .groupBy('CODE') \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed('count', 'COUNT') \\\n",
    "        .filter(col('COUNT') >= support_threshold)\n",
    "    \n",
    "    frequent_diseases_k1.write.mode('overwrite').parquet(path='frequent_diseases_k1', compression='gzip')\n",
    "\n",
    "else:\n",
    "    frequent_diseases_k1 = spark.read.parquet('frequent_diseases_k1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_diseases_k1_set = {r.CODE for r in frequent_diseases_k1.select('CODE').collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frequent_diseases_k1_set)   # 131"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(ArrayType(StringType(), False), False))\n",
    "def combine_pairs(elems: Iterable[Any]):\n",
    "    return list(combinations(elems, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(PATIENT='0000584e-c2d3-436b-8bd2-16294a3889b3', collect_list(CODE)=['195662009', '128613002', '703151001', '70704007', '65363002', '192127007', '232353008', '444814009'], CODE_PAIRS=[['195662009', '128613002'], ['195662009', '703151001'], ['195662009', '70704007'], ['195662009', '65363002'], ['195662009', '192127007'], ['195662009', '232353008'], ['195662009', '444814009'], ['128613002', '703151001'], ['128613002', '70704007'], ['128613002', '65363002'], ['128613002', '192127007'], ['128613002', '232353008'], ['128613002', '444814009'], ['703151001', '70704007'], ['703151001', '65363002'], ['703151001', '192127007'], ['703151001', '232353008'], ['703151001', '444814009'], ['70704007', '65363002'], ['70704007', '192127007'], ['70704007', '232353008'], ['70704007', '444814009'], ['65363002', '192127007'], ['65363002', '232353008'], ['65363002', '444814009'], ['192127007', '232353008'], ['192127007', '444814009'], ['232353008', '444814009']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .filter(col('CODE').isin(frequent_diseases_k1_set)) \\\n",
    "    .groupBy('PATIENT') \\\n",
    "    .agg(collect_list('CODE')) \\\n",
    "    .withColumn('CODE_PAIRS', combine_pairs('collect_list(CODE)')) \\\n",
    "    .first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_example = df \\\n",
    "    .filter(col('CODE').isin(frequent_diseases_k1_set)) \\\n",
    "    .groupBy('PATIENT') \\\n",
    "    .agg(collect_list('CODE')) \\\n",
    "    .withColumn('CODE_PAIRS', combine_pairs('collect_list(CODE)')) \\\n",
    "    .first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_example['collect_list(CODE)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_example.CODE_PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from pyspark.sql import Row\n",
    "\n",
    "    df_test = spark.createDataFrame([\n",
    "        Row(a=0, b=[1,2,3,8], c=list(combinations([1,2,3,8], 2))),\n",
    "        Row(a=1, b=[4,5,6], c=list(combinations([4,5,6], 2))),\n",
    "        Row(a=2, b=[1,5,7], c=list(combinations([1,5,7], 2))),\n",
    "    ])\n",
    "\n",
    "    df_test.withColumn('c', explode('c')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('frequent_diseases_k2'):\n",
    "    # ???\n",
    "    frequent_diseases_k2 = df \\\n",
    "        .filter(col('CODE').isin(frequent_diseases_k1_set)) \\\n",
    "        .groupBy('PATIENT') \\\n",
    "        .agg(collect_list('CODE')) \\\n",
    "        .withColumn('CODE_PAIRS', combine_pairs('collect_list(CODE)')) \\\n",
    "        .select('PATIENT', 'CODE_PAIRS') \\\n",
    "        .withColumn('CODE_PAIR', explode('CODE_PAIRS')) \\\n",
    "        .drop('CODE_PAIRS') \\\n",
    "        .withColumn('CODE_PAIR', array_sort('CODE_PAIR')) \\\n",
    "        .groupBy('CODE_PAIR') \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed('count', 'COUNT') \\\n",
    "        .filter(col('COUNT') >= support_threshold)\n",
    "    \n",
    "    frequent_diseases_k2.write.mode('overwrite').parquet(path='frequent_diseases_k2', compression='gzip')\n",
    "\n",
    "else:\n",
    "    frequent_diseases_k2 = spark.read.parquet('frequent_diseases_k2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "frequent_diseases_k2_set = {tuple(r.CODE_PAIR) for r in frequent_diseases_k2.select('CODE_PAIR').collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2940"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequent_diseases_k2_set)   # 2940"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(ArrayType(StringType(), False), False))\n",
    "def combine_triples(elems: Iterable[Any]):\n",
    "\n",
    "    triples = list(combinations(elems, 3))\n",
    "\n",
    "    triples = [\n",
    "        combination for combination in triples\n",
    "        if ((combination[0], combination[1]) in frequent_diseases_k2_set\n",
    "            and (combination[0], combination[2]) in frequent_diseases_k2_set\n",
    "            and (combination[1], combination[2]) in frequent_diseases_k2_set)\n",
    "    ]\n",
    "        \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('frequent_diseases_k3'):\n",
    "    frequent_diseases_k3 = df \\\n",
    "        .filter(col('CODE').isin(frequent_diseases_k1_set)) \\\n",
    "        .groupBy('PATIENT') \\\n",
    "        .agg(collect_list('CODE')) \\\n",
    "        .withColumn('collect_list(CODE)', array_sort('collect_list(CODE)')) \\\n",
    "        .withColumn('CODE_TRIPLES', combine_triples('collect_list(CODE)')) \\\n",
    "        .select('PATIENT', 'CODE_TRIPLES') \\\n",
    "        .withColumn('CODE_TRIPLE', explode('CODE_TRIPLES')) \\\n",
    "        .drop('CODE_TRIPLES') \\\n",
    "        .groupBy('CODE_TRIPLE') \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed('count', 'COUNT') \\\n",
    "        .filter(col('COUNT') >= support_threshold)\n",
    "\n",
    "    frequent_diseases_k3.write.mode('overwrite').parquet(path='frequent_diseases_k3', compression='gzip')\n",
    "\n",
    "else:\n",
    "    frequent_diseases_k3 = spark.read.parquet('frequent_diseases_k3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "frequent_diseases_k3_set = {tuple(r.CODE_TRIPLE) for r in frequent_diseases_k3.select('CODE_TRIPLE').collect()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequent_diseases_k3_set) # 13395"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output\n",
    "\n",
    "```\n",
    "...\n",
    "{Diabetes, Neoplasm} -> {Colon polyp}: 0.2000, ...\n",
    "...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
