{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, ArrayType\n",
    "from itertools import combinations\n",
    "from typing import Iterable, Any"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/02/24 18:47:45 WARN Utils: Your hostname, martinho-SATELLITE-L50-B resolves to a loopback address: 127.0.1.1; using 192.168.1.66 instead (on interface enp8s0)\n",
      "23/02/24 18:47:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/martinho/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/02/24 18:47:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('SandboxAssign1') \\\n",
    "    .config('spark.master', 'local[4]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .csv('conditions.csv.gz') \\\n",
    "    .drop('START', 'STOP', 'ENCOUNTER') \\\n",
    "    .withColumn('CODE', col('CODE').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_description_df = df \\\n",
    "    .select('CODE', 'DESCRIPTION') \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('DESCRIPTION').distinct()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-priori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_threshold = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_diseases_k1 = df.select('CODE', lit(1).alias('COUNT')) \\\n",
    "    .groupBy('CODE') \\\n",
    "    .sum('COUNT') \\\n",
    "    .withColumnRenamed('sum(count)', 'COUNT') \\\n",
    "    .filter(col('COUNT') >= support_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "frequent_diseases_k1.write.mode('overwrite').option('header', True).csv(path='frequent_diseases_k1', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "frequent_diseases_k1_set = {r.CODE for r in frequent_diseases_k1.select('CODE').collect()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=ArrayType(ArrayType(IntegerType()), False))\n",
    "def combine_pairs(elems: Iterable[Any]):\n",
    "    return list(combinations(elems, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           CODE_PAIR|COUNT|\n",
      "+--------------------+-----+\n",
      "|[127013003, 23069...| 2609|\n",
      "|[230690007, 12690...| 2870|\n",
      "|[15777000, 44465007]|15974|\n",
      "|[19169002, 79586000]|12985|\n",
      "|[44054006, 196416...| 2128|\n",
      "|[444814009, 39921...| 8152|\n",
      "|[443165006, 26929...| 1887|\n",
      "|[239872002, 42825...|  773|\n",
      "|[65966004, 15777000]| 7194|\n",
      "|[88805009, 16114001]| 1222|\n",
      "|[162864005, 87433...| 4285|\n",
      "|[44465007, 44054006]| 3462|\n",
      "|[162864005, 25463...| 3197|\n",
      "|[403190006, 12690...|  353|\n",
      "|[254837009, 58150...|  466|\n",
      "|[230690007, 82423...| 1666|\n",
      "|[307731004, 70704...|  356|\n",
      "|[62106007, 275272...|  207|\n",
      "|[16114001, 65966004]|  844|\n",
      "|[84757009, 19169002]| 1467|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_pass_k1 = df \\\n",
    "    .filter(col('CODE').isin(frequent_diseases_k1_set)) \\\n",
    "    .groupBy('PATIENT') \\\n",
    "    .agg(collect_list('CODE')) \\\n",
    "    .withColumn('CODE', combine_pairs('collect_list(CODE)')) \\\n",
    "    .select(explode('CODE').alias('CODE_PAIR'), lit(1).alias('COUNT')) \\\n",
    "    .groupBy('CODE_PAIR') \\\n",
    "    .sum('COUNT') \\\n",
    "    .withColumnRenamed('sum(COUNT)', 'COUNT')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output\n",
    "\n",
    "```\n",
    "...\n",
    "{Diabetes, Neoplasm} -> {Colon polyp}: 0.2000, ...\n",
    "...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
